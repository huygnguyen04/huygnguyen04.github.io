---
permalink: /
title: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---


<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=0.85">
    <title>Huy Nguyen's Portfolio</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/remixicon/3.4.0/remixicon.css" crossorigin="">
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            padding: 20px;
            margin-bottom: 100px;
            background: #fff;
        }

        .awards-container {
            margin-top: 20px;
        }
        .award {
            background-color: #f9f9f9;
            border-left: 5px solid #3f51b5;
            margin-bottom: 20px;
            padding: 10px 20px;
            border-radius: 4px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .award-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 10px;
        }
        .award-title {
            display: flex;
            align-items: center;
        }
        .award-icon {
            margin-right: 10px;
            width: 40px;
        }
        .award h2 {
            margin: 0;
            padding-top: 10px;
            font-size: 17.5px;
        }
        .award p {
            margin: 0;
            font-size: 15px;
            line-height: 1.5;
        }
        .certificate-link {
            display: inline-block;
            padding: 6px 12px;
            background: linear-gradient(45deg, #3f51b5, #7986cb);
            color: white;
            text-decoration: none;
            border-radius: 20px;
            font-size: 13px;
            transition: all 0.3s ease;
            box-shadow: 0 2px 5px rgba(0,0,0,0.2);
            margin-left: 15px;
        }
        .certificate-link:hover {
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.3);
            background: linear-gradient(45deg, #303f9f, #5c6bc0);
        }
        .certificate-link i {
            margin-right: 5px;
        }
        .award.dark-mode .certificate-link {
            background: linear-gradient(45deg, #bb86fc, #9d46ff);
        }
        .award.dark-mode .certificate-link:hover {
            background: linear-gradient(45deg, #9d46ff, #bb86fc);
        }
    </style>
</head>
<body>

<section id="introduction">
    <style>
        #introduction h1 { font-size: 20px; }
        #introduction p { font-size: 14px; line-height: 1.5; }
        #introduction h3 { font-size: 14px; font-weight: 600; }
    </style>
    <h1>Introduction</h1>
    <hr>
    <p>Hi there! ðŸ‘‹ I'm Huy Nguyen, a fourth-year Undergraduate researcher at the University of Virginia pursuing a Bachelor's degree in Computer Science with a minor in Applied Mathematics.</p>
    <p>Originally from Ho Chi Minh City, Vietnam, I moved to the United States as an international student with aspirations to pursue a Ph.D. in Computer Science.</p>
    <p>I am currently conducting research in <em>Hardware Architecture and Acceleration</em> at the <a href="https://www.cs.virginia.edu/~skadron/">Lava Lab</a> under <a href="https://www.cs.virginia.edu/~skadron/">Prof. Kevin Skadron</a>, where I'm working on innovating the Rodinia Benchmark. Previously, I was involved in GPU research at the <a href="https://insight-cal.github.io/">Insight Lab</a> under Prof. Adwait Jog.</p>
    <p>My research interests lie in hardware optimization and parallel computing, with particular expertise in CUDA programming, NVIDIA technologies, and microarchitectural optimizations.</p>
    <p>Beyond research, I serve as a <a href="https://huynguyen04.github.io/teaching/">Teaching Assistant and Grader</a> for Computer Science and Applied Mathematics courses, where I find fulfillment in mentoring and supporting fellow students.</p>
    <h3>I am actively searching for PhD programs for this upcoming 2025 application cycle! I am specifically interested in universities with labs working on computer architecture with an emphasis on GPU architecture, performance modeling, and reproducible benchmarking.</h3>
</section>

<br>
<section id="research">
  <style>
    /* Scoped to this section */
    #research { font-size: 14px; }
    #research .award { margin-bottom: 18px; }
    #research .award-header { display: flex; align-items: flex-start; justify-content: space-between; gap: 12px; }
    #research .title-col { flex: 1 1 auto; }
    #research h1 { font-size: 22px; margin: 0 0 8px 0; }
    #research h2 { margin: 0 0 4px 0; font-size: 16px; font-weight: 700; }
    #research p { margin: 0 0 9px 0; font-size: 14px; line-height: 1.55; }

    /* Meta row on the left (advisor only) */
    #research .meta-row {
      display: flex;
      justify-content: flex-start;
      align-items: baseline;
      gap: 8px;
      margin: 0 0 8px 0;
      font-size: 12.5px;
      font-weight: 600;
      color: #444;
    }

    /* Right side: buttons on top, timeline right below */
    #research .links { display: flex; flex-direction: column; align-items: flex-end; gap: 6px; white-space: nowrap; }
    #research .btn-row { display: flex; gap: 10px; }
    #research .timeline { font-size: 12.5px; font-weight: 600; color: #555; }

    /* Pill buttons */
    #research .btn-pill {
      display: inline-flex;
      align-items: center;
      gap: 6px;
      padding: 7px 14px;
      border-radius: 999px;
      font-size: 12.5px;
      font-weight: 700;
      color: #fff;
      text-decoration: none;
      background: linear-gradient(135deg, #6973d8 0%, #6f7eea 100%);
      box-shadow: 0 6px 14px rgba(0,0,0,0.15);
      border: 1px solid rgba(255,255,255,0.25);
      transition: transform .15s ease, box-shadow .15s ease, filter .15s ease;
    }
    #research .btn-pill:hover { transform: translateY(-1px); box-shadow: 0 10px 18px rgba(0,0,0,0.2); filter: brightness(1.03); }
    #research .btn-pill:active { transform: translateY(0); box-shadow: 0 6px 12px rgba(0,0,0,0.16); }
    #research .btn-pill i { font-size: 13px; }
  </style>

  <h1>Research Interests & Experience</h1>
  <hr>

  <p>
    Moore's Law is running into physical and economic limitsâ€”shrinking transistors no longer guarantees easy speedups.
    To keep improving performance, we have to go beyond scaling with smarter microarchitectures, tighter memory and interconnect design,
    and software that actually exploits these features. That motivates my work in Computer Architecture and Hardware Acceleration with a specific emphasis on GPUs:
    I am interested in building reproducible benchmarking and feature-isolating microbenchmarks that explain where performance comes from and how to unlock it on real-life workloads.
  </p>

  <p>
    Below are my research projects addressing these challenges, advised by amazing professors and labs at UVA.
  </p>

  <!-- LAVA Lab / Rodinia v4.0 (Ongoing) -->
  <div class="award">
    <div class="award-header">
      <div class="title-col">
        <h2>Rodinia Benchmark v4.0 â€” Modernizing Benchmarks for Emerging GPU Architectures (LAVA Lab, UVA)</h2>
        <div class="meta-row">Advised by Prof. Kevin Skadron</div>
      </div>
      <div class="links">
        <div class="btn-row">
          <a class="btn-pill" href="https://github.com/huygnguyen04/gpu-rodinia-v4.0" target="_blank" rel="noopener">
            <i class="ri-external-link-line"></i> Project
          </a>
        </div>
        <div class="timeline">May 2025 â€“ present Â· Ongoing</div>
      </div>
    </div>
    <p>
      I am leading the modernization of Rodinia for CUDA 12+, larger datasets, and contemporary GPU features such as Tensor Cores, Cooperative Groups, and multi-GPU. I built a reproducible harness to compare legacy versus modernized implementations across GPU generations and created microbenchmarks that isolate memory hierarchy, warp scheduling, and synchronization effects. Using Nsight tooling and GPGPU-Sim, I focus on making results explainable so architectural choices map cleanly to application-level behavior.
    </p>
  </div>

  <!-- GPU L2 Cache Optimizer (Completed) -->
  <div class="award">
    <div class="award-header">
      <div class="title-col">
        <h2>GPU L2 Cache Architecture Exploration with GPGPU-Sim</h2>
        <div class="meta-row">Advised by Prof. Kevin Skadron</div>
      </div>
      <div class="links">
        <div class="btn-row">
          <a class="btn-pill" href="https://github.com/huygnguyen04/GPU-L2-Cache-Optimizer" target="_blank" rel="noopener">
            <i class="ri-external-link-line"></i> Project
          </a>
        </div>
        <div class="timeline">Feb 2025 â€“ May 2025 Â· Completed</div>
      </div>
    </div>
    <p>
      I simulated extended L2 cache designs in GPGPU-Sim and co-modeled area and latency with CACTI to study bandwidthâ€“latency trade-offs, hit-rate impacts, and workload sensitivity. I evaluated design points with Rodinia and ML kernels, scripted parameter sweeps, and analyzed how cache capacity and organization shape end-to-end performance. This study complements my benchmark modernization by tying memory-system choices to observed kernel behavior.
    </p>
  </div>

  <!-- Insight Lab / LLM-driven CUDA & MLPerf (Completed) -->
  <div class="award">
    <div class="award-header">
      <div class="title-col">
        <h2>LLM-Driven CUDA Optimization & MLPerf Profiling (Insight Lab)</h2>
        <div class="meta-row">Advised by Prof. Adwait Jog</div>
      </div>
      <div class="links">
        <div class="btn-row">
          <a class="btn-pill" href="https://github.com/huygnguyen04/PyTorch-CUDA-ML-Performance" target="_blank" rel="noopener">
            <i class="ri-external-link-line"></i> Project
          </a>
        </div>
        <div class="timeline">May 2024 â€“ Aug 2024 Â· Completed</div>
      </div>
    </div>
    <p>
      I implemented core ML operators directly in CUDA and compared hand-tuned kernels with PyTorch implementations and LLM-generated CUDA. I developed an iterative feedback pipeline that guides LLMs to refine kernels and profiled results across architectures and workloads using MLPerf. The goal was not only to measure how fast things run but to explain why performance differs by uncovering memory access, scheduling, and fusion bottlenecks hidden by higher-level abstractions.
    </p>
  </div>

  <!-- ELM Group / GPUMD + NEP (Completed) -->
  <div class="award">
    <div class="award-header">
      <div class="title-col">
        <h2>GPU-Accelerated Molecular Dynamics & NEP Modeling (ELM Group, UVA Materials Science)</h2>
        <div class="meta-row">Advised by Prof. Keivan Esfarjani</div>
      </div>
      <div class="links">
        <div class="btn-row">
          <a class="btn-pill" href="https://github.com/huygnguyen04/GPUMD-UVA" target="_blank" rel="noopener">
            <i class="ri-external-link-line"></i> Project
          </a>
          <a class="btn-pill" href="https://doi.org/10.1063/5.0224282" target="_blank" rel="noopener">
            <i class="ri-external-link-line"></i> Paper
          </a>
        </div>
        <div class="timeline">Apr 2023 â€“ Jan 2025 Â· Completed</div>
      </div>
    </div>
    <p>
      I built a GPU-first, reproducible MD workflow for entropy-stabilized oxides using GPUMD and a Neuroevolution ML Potential. I automated large simulation batches with SLURM job arrays, improved NEP training on GPUs to reduce energy and force error, and analyzed thermal trends across temperatures and compositions. The project culminated in a Journal of Applied Physics publication and seeded my interest in the hardwareâ€“software interface that ultimately drives performance.
    </p>
  </div>
</section>
